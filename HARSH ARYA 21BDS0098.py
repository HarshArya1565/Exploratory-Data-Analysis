# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cKiw37vWVTfWE3JprTHcEoRJDFCFWcPA

# **MODULE 2**
"""

import pandas as pd

# Assuming the last four digits of the Roll Number (R.no) are 0098
roll_number_last4_0098 = 98  # last 4 digits of your Roll Number (0098)

# DataFrame 1: Fname - ProductID, NameofProd, Price
HarshArya1 = {
    'ProductID': [roll_number_last4, roll_number_last4 + 1, roll_number_last4 + 2, roll_number_last4 + 3, roll_number_last4 + 4],
    'NameofProd': ['Product_A', 'Product_B', 'Product_C', 'Product_D', 'Product_E'],
    'Price': [100, 200, 300, 400, 500]
}

df1_0098 = pd.DataFrame(HarshArya1)

# DataFrame 2: Lname - ProductID, Company_Location
HarshArya2 = {
    'ProductID': [roll_number_last4, roll_number_last4 + 1, roll_number_last4 + 2, roll_number_last4 + 3, roll_number_last4 + 4],
    'Company_Location': ['Location_1', 'Location_2', 'Location_3', 'Location_4', 'Location_5']
}

df2_0098 = pd.DataFrame(HarshArya2)

# Show both DataFrames
print("DataFrame 1 (Fname):")
print(df1_0098)
print("\nDataFrame 2 (Lname):")
print(df2_0098)

# 1. Append (rows): Append df2 to df1 using pd.concat() (This will work if the columns are the same in both DataFrames)
df_append_0098 = pd.concat([df1_0098, df2_0098], ignore_index=True)
print("\nDataFrame after Appending df2 to df1 using pd.concat():")
print(df_append_0098)

# 2. Concatenate: Concatenate df1 and df2 by columns (aligning them side by side)
df_concat_0098 = pd.concat([df1_0098, df2_0098], axis=1)
print("\nDataFrame after Concatenating df1 and df2:")
print(df_concat_0098)

# 3. Merge: Merge df1 and df2 on 'ProductID' (similar to SQL join)
df_merge_0098 = pd.merge(df1_0098, df2_0098, on='ProductID', how='inner')
print("\nDataFrame after Merging df1 and df2 on 'ProductID':")
print(df_merge_0098)

# 4. Join: Join df1 and df2 on the index (this will work only if the indexes align)
df_join_0098 = df1_0098.set_index('ProductID').join(df2_0098.set_index('ProductID'))
print("\nDataFrame after Joining df1 and df2 on the index:")
print(df_join_0098)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load the fruits.csv file into Python (make sure to specify the correct file path)
HarshArya = pd.read_csv("fruits.csv")

# Display the first few rows of the dataframe
print("Original DataFrame:")
print(HarshArya.head())

# 2. Insert the first record as 'Your name, Rollno (last 4 digits), roll no, roll no, roll no, NaN)
# Assuming your name is 'John Doe' and roll number last 4 digits are 0098 (change as needed)
first_record_0098 = {
    'Name': 'John Doe',
    'RollNo': 98,
    'Store1': np.nan,
    'Store2': np.nan,
    'Store3': np.nan,
    'Store4': np.nan,
    'Store5': np.nan
}

# Convert the first record to a DataFrame and concatenate it with the existing DataFrame
first_record_df_0098 = pd.DataFrame([first_record_0098])
HarshArya = pd.concat([first_record_df_0098, HarshArya], ignore_index=True)

# Display the updated dataframe
print("\nUpdated DataFrame with First Record:")
print(HarshArya.head())

# 3. Check if there exists any NA (missing values) in the dataset
any_na_0098 = fruits.isna().any().any()  # Check if any NaN value exists in the dataframe
print(f"\nDoes the dataset contain any missing values? {any_na_0098}")

# 4. Finding the missing summaries of the dataset (summary of missing values per column)
missing_summary_0098 = HarshArya.isna().sum()
print("\nMissing Values Summary (per column):")
print(missing_summary_0098)

# 5. Find the total number of NA (missing values) in the dataset
total_na_0098 = HarshArya.isna().sum().sum()  # Total missing values in the dataframe
print(f"\nTotal number of missing values in the dataset: {total_na_0098}")

# 6. Count the total number of complete cases in Store4 and Store5
complete_cases_0098 = HarshArya[['Store4', 'Store5']].notna().all(axis=1).sum()
print(f"\nTotal number of complete cases in Store4 and Store5: {complete_cases_0098}")

# 7. Proportion of missing and complete data
prop_missing_0098 = HarshArya.isna().mean()  # Proportion of missing values per column
prop_complete_0098 = 1 - prop_missing_0098  # Proportion of complete values per column
print("\nProportion of Missing Values per Column:")
print(prop_missing_0098)
print("\nProportion of Complete Values per Column:")
print(prop_complete_0098)

# 8. Display the missing values per column for each observation
# Create a missing data heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(HarshArya.isna(), cbar=False, cmap='viridis')
plt.title("Missing Data Heatmap")
plt.show()

# 9. Performing row-wise deletion (drop rows with any missing values)
fruits_cleaned_0098 = HarshArya.dropna()

# Display the cleaned dataframe
print("\nDataFrame after Row-wise Deletion (NaN Rows Removed):")
print(fruits_cleaned_0098.head())

# Optionally, check the number of rows before and after row deletion
print(f"\nNumber of rows before deletion: {len(HarshArya)}")
print(f"Number of rows after deletion: {len(fruits_cleaned_0098)}")

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the Dataset
# Load the dataset (Replace 'path_to_file.csv' with your actual file path)
HarshArya = pd.read_csv("data(1).csv")

# Step 2: Convert all column names to lowercase
HarshArya.columns = HarshArya.columns.str.lower()

# Step 3: Replace '?' with NaN for all columns
HarshArya.replace('?', np.nan, inplace=True)

# Step 4: Display the number of rows and columns in the dataset
print("Dimensions of the dataset:", HarshArya.shape)

# Step 5: Display the header or attribute names from the dataset
print("Column names:", HarshArya.columns)

# Step 6: Display the structure of the dataset (info)
print("Structure of the dataset:")
HarshArya.info()

# Step 7: View the first 3 and last 3 rows of the dataset
print("First 3 rows of the dataset:")
print(HarshArya.head(3))

print("Last 3 rows of the dataset:")
print(HarshArya.tail(3))

# Step 8: Deleting Specific Columns (Fuel-System and Bore) by Index and Select Function
# Deleting columns 'fuel-system' and 'bore' by column index (assuming known column indices)
HarshArya = HarshArya.drop(HarshArya.columns[[9, 11]], axis=1)  # Adjust indices accordingly

# Deleting columns using pandas' `drop` (select function not needed in pandas)
HarshArya = HarshArya.drop(columns=['fuel-system', 'bore'])

# Step 9: Displaying Summary Statistics
print("Summary Statistics of the dataset:")
print(HarshArya.describe())

# Step 10: Data Cleaning

# 10.1 Find out the number of values that are not numeric in 'price', 'horsepower', and 'normalized-losses'
non_numeric_price_0098 = HarshArya['price'].apply(pd.to_numeric, errors='coerce').isna().sum()
non_numeric_horsepower_0098 = HarshArya['horsepower'].apply(pd.to_numeric, errors='coerce').isna().sum()
non_numeric_normalized_losses_0098 = HarshArya['normalized-losses'].apply(pd.to_numeric, errors='coerce').isna().sum()

print(f"Non-numeric values in 'price': {non_numeric_price_0098}")
print(f"Non-numeric values in 'horsepower': {non_numeric_horsepower_0098}")
print(f"Non-numeric values in 'normalized-losses': {non_numeric_normalized_losses_0098}")

# 10.2 Setting the missing value in 'price' to the mean and converting to numeric
HarshArya['price'] = pd.to_numeric(HarshArya['price'], errors='coerce')
mean_price_0098 = HarshArya['price'].mean()
HarshArya['price'].fillna(mean_price_0098, inplace=True)

# Step 11: Compute Measures of Central Tendency and Dispersion for 'height' Column

# 11.1 Central Tendency: Mean, Median, Mode
mean_height_0098 = HarshArya['height'].mean()
median_height_0098 = HarshArya['height'].median()
mode_height_0098 = HarshArya['height'].mode()[0]

print(f"Mean of height: {mean_height_0098}")
print(f"Median of height: {median_height_0098}")
print(f"Mode of height: {mode_height_0098}")

# 11.2 Dispersion: Standard Deviation and Variance
sd_height_0098 = HarshArya['height'].std()
var_height_0098 = HarshArya['height'].var()

print(f"Standard Deviation of height: {sd_height_0098}")
print(f"Variance of height: {var_height_0098}")

# 11.3 Quartile Ranges and IQR
height_quantiles_0098 = HarshArya['height'].quantile([0.25, 0.5, 0.75])
iqr_height_0098 = height_quantiles_0098[0.75] - height_quantiles_0098[0.25]

print(f"Quartiles of height:\n{height_quantiles_0098}")
print(f"Interquartile Range (IQR) of height: {iqr_height_0098}")

# Step 12: Calculate Correlation Between Price and Horsepower
cor_price_hp = HarshArya[['price', 'horsepower']].corr().iloc[0, 1]
print(f"Correlation between price and horsepower: {cor_price_hp}")

# Step 13: Univariate Analysis (Plots)

# 13.1 Distribution Plot: Histogram for height
plt.figure(figsize=(8, 6))
plt.hist(HarshArya['height'], bins=20, color='lightblue', edgecolor='black')
plt.title('21BDS0098 - Height Distribution Plot')
plt.xlabel('Height')
plt.ylabel('Frequency')
plt.show()

# Histogram for height using Seaborn
sns.histplot(HarshArya['height'], kde=False, bins=20, color='lightblue')
plt.title('21BDS0098 - Height Distribution Plot')
plt.xlabel('Height')
plt.ylabel('Frequency')
plt.show()

# 13.2 Distribution Plot Histogram for price
plt.figure(figsize=(8, 6))
plt.hist(HarshArya['price'], bins=20, color='lightgreen', edgecolor='black')
plt.title('21BDS0098 - Price Distribution Plot')
plt.xlabel('price')
plt.ylabel('Frequency')
plt.show()

# Histogram for price using Seaborn
sns.histplot(HarshArya['price'], kde=False, bins=20, color='lightgreen')
plt.title('21BDS0098 - Price Distribution Plot')
plt.xlabel('price')
plt.ylabel('Frequency')
plt.show()

# 13.3 Distribution Plot Density for price
plt.figure(figsize=(8, 6))
sns.kdeplot(HarshArya['price'], shade=True, color='purple')
plt.title('21BDS0098 - Price Density Plot')
plt.xlabel('price')
plt.ylabel('Density')
plt.show()

# 13.4 Distribution Plot (Histogram + Density for price)
plt.figure(figsize=(8, 6))
sns.histplot(HarshArya['price'], kde=True, bins=20, color='lightgreen', line_kws={'color': 'purple'})
plt.title('21BDS0098 - Price Histogram and Density Plot')
plt.xlabel('price')
plt.ylabel('Frequency/Density')
plt.show()

# 13.5 Boxplot for price
plt.figure(figsize=(8, 6))
sns.boxplot(x=HarshArya['price'], color='lightblue')
plt.title('21BDS0098 - Price Boxplot')
plt.xlabel('price')
plt.show()

# 13.6 Display a Barplot for 'no-of-cylinders' (Vertical and Horizontal)

# Check if 'no-of-cylinders' exists in the column names
if 'no-of-cylinders' in HarshArya.columns:
    # Vertical Barplot
    plt.figure(figsize=(8, 6))
    sns.countplot(x='no-of-cylinders', HarshArya=HarshArya, palette='Blues')
    plt.title('21BDS0098 - Barplot of Number of Cylinders')
    plt.xlabel('Number of Cylinders')
    plt.ylabel('Count')
    plt.show()

    # Horizontal Barplot
    plt.figure(figsize=(8, 6))
    sns.countplot(y='no-of-cylinders', HarshArya=HarshArya, palette='Blues')
    plt.title('21BDS0098 - Barplot of Number of Cylinders')
    plt.xlabel('Count')
    plt.ylabel('Number of Cylinders')
    plt.show()

else:
    print("'no-of-cylinders' column not found in the dataset.")
    # You can check other columns that might be similar or adjust the code accordingly
    print("Available columns:", HarshArya.columns)

# 13.7 Display Pie Plot for Drive-Wheel
drive_wheel_counts = HarshArya['drive-wheels'].value_counts()
plt.figure(figsize=(8, 6))
plt.pie(drive_wheel_counts, labels=drive_wheel_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set2'))
plt.title('21BDS0098 - Pie Chart for Drive-Wheel')
plt.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.
plt.show()

# 13.8 Display Dot Plot for 'price'
plt.figure(figsize=(8, 6))
sns.stripplot(x=HarshArya['price'], color='purple', jitter=True, size=6)
plt.title('21BDS0098 - Dot Plot for Price')
plt.xlabel('Price')
plt.show()

"""# **MODULE** **3**"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset (replace 'data.csv' with the actual path to your CSV file)
HarshArya = pd.read_csv('data(1).csv')

# Step 1: Replace '?' with NaN (if applicable)
HarshArya.replace('?', np.nan, inplace=True)

# Step 2: Convert columns that should be numeric to numeric, coercing errors to NaN
# Example: Convert 'horsepower' and 'price' columns to numeric
HarshArya['horsepower'] = pd.to_numeric(HarshArya['horsepower'], errors='coerce')
HarshArya['price'] = pd.to_numeric(HarshArya['price'], errors='coerce')

# Step 3: Handle missing values after conversion to numeric (impute missing values)
# Fill missing values for numeric columns with the mean
numeric_cols_0098 = HarshArya.select_dtypes(include=['float64', 'int64']).columns
HarshArya[numeric_cols_0098] = HarshArya[numeric_cols_0098].fillna(HarshArya[numeric_cols_0098].mean())

# Step 4: Handle missing values in non-numeric columns by using the mode (most frequent value)
non_numeric_cols_0098 = HarshArya.select_dtypes(exclude=['float64', 'int64']).columns
for col in non_numeric_cols_0098:
    HarshArya[col] = HarshArya[col].fillna(HarshArya[col].mode()[0])

# Step 5: Check for remaining missing values
print("Missing values after imputation:\n", HarshArya.isna().sum())

# Bivariate and Multivariate Analysis

# 1. Categorical vs Categorical: Stacked Bar Plot (engine-location vs num-of-doors)
sns.countplot(data=HarshArya, x="engine-location", hue='num-of-doors', dodge=False, palette='Set2')
plt.title("21BDS0098 - Stacked Bar Plot: Engine Location vs Num of Doors")
plt.xlabel('Engine Location')
plt.ylabel('Count')
plt.show()

# 2. Categorical vs Quantitative: Bar Plot (Price vs Engine Location)
sns.barplot(data=HarshArya, x='engine-location', y='price', palette='Set2')
plt.title("21BDS0098 - Bar Chart: Price vs Engine Location")
plt.xlabel('Engine Location')
plt.ylabel('Price')
plt.show()

# 3. Quantitative vs Quantitative: Scatter Plot (Price vs Horsepower)
sns.scatterplot(data=HarshArya, x='price', y='horsepower', hue='engine-location', palette='Set2')
plt.title("21BDS0098 - Scatter Plot: Price vs Horsepower")
plt.xlabel('Price')
plt.ylabel('Horsepower')
plt.show()

# 4. Quantitative vs Quantitative: Heatmap (Correlation matrix)
numeric_data_0098 = HarshArya.select_dtypes(include=['number'])
corr_matrix_0098 = numeric_data_0098.corr()   # Calculate correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix_0098, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title("21BDS0098 - Heatmap of Correlation Matrix")
plt.show()

# 5. Categorical vs Quantitative: Density Plot (Price vs Engine Location)
sns.kdeplot(data=HarshArya, x='price', hue='engine-location', fill=True, palette='Set2')
plt.title("21BDS0098 - Density Plot: Price vs Engine Location")
plt.xlabel('Price')
plt.ylabel('Density')
plt.show()

# 6. Categorical vs Quantitative: Box Plot (Price vs Engine Location)
sns.boxplot(data=HarshArya, x='engine-location', y='price', palette='Set2')
plt.title("21BDS0098 - Box Plot: Price vs Engine Location")
plt.xlabel('Engine Location')
plt.ylabel('Price')
plt.show()

# 7. Categorical vs Quantitative: Violin Plot (Price vs Engine Location)
sns.violinplot(data=HarshArya, x='engine-location', y='price', palette='Set2')
plt.title("21BDS0098 - Violin Plot: Price vs Engine Location")
plt.xlabel('Engine Location')
plt.ylabel('Price')
plt.show()

# 8. Multivariate: Scatter Plot (using color as third variable)
sns.scatterplot(data=HarshArya, x='price', y='horsepower', hue='engine-location', size='curb-weight', palette='Set2', sizes=(20, 200))
plt.title("21BDS0098 - Scatter Plot: Price vs Horsepower (With Size and Color)")
plt.xlabel('Price')
plt.ylabel('Horsepower')
plt.show()

# 9. Bubble Plot (with x, y, and size)
sns.scatterplot(data=HarshArya, x='price', y='horsepower', hue='engine-location', size='curb-weight', sizes=(20, 200), palette='Set2')
plt.title("21BDS0098 - Bubble Plot: Price vs Horsepower")
plt.xlabel('Price')
plt.ylabel('Horsepower')
plt.show()

# 10. Display a graph into sub-graphs (Faceting)
sns.displot(data=HarshArya, x='price', col='engine-location', kde=True, facet_kws={'margin_titles': True})
plt.suptitle("21BDS0098 - Distribution of Price by Engine Location")
plt.show()

# 11. Display a graph into sub-graphs (Facet Grid)
sns.FacetGrid(HarshArya, col='engine-location').map(sns.histplot, 'price', kde=True)
plt.suptitle("21BDS0098 - Facet Grid: Price Distribution by Engine Location")
plt.show()

# Bivariate Analysis - Contingency Table (Categorical vs Categorical)

# Create a contingency table for "engine-location" and "num-of-doors"
contingency_table = pd.crosstab(HarshArya['engine-location'],HarshArya['num-of-doors'])
print("Contingency Table for Engine Location vs Num of Doors:")
print(contingency_table)

# Stacked bar chart for engine-location vs num-of-doors
# 1. Using Matplotlib
contingency_table.plot(kind='bar', stacked=True, color=['skyblue', 'lightgreen'])
plt.title("21BDS0098 - Stacked Bar Chart: Engine Location vs Num of Doors")
plt.xlabel('Engine Location')
plt.ylabel('Count')
plt.show()

# 2. Using Seaborn
sns.barplot(data=HarshArya, x='engine-location', hue='num-of-doors', dodge=False, palette='Set2')
plt.title("21BDS0098 - Stacked Bar Plot: Engine Location vs Num of Doors")
plt.xlabel('Engine Location')
plt.ylabel('Count')
plt.show()

# 3. Grouped bar plot (side-by-side plot)
sns.barplot(data=HarshArya, x='engine-location', hue='num-of-doors', palette='Set2', ci=None)
plt.title("21BDS0098 - Grouped Bar Plot: Engine Location vs Num of Doors")
plt.xlabel('Engine Location')
plt.ylabel('Count')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# 1. Simulate the AirPassengers dataset
# Let's create the dataset with monthly passenger data from 1949 to 1960

date_range = pd.date_range(start='1949-01-01', end='1960-12-01', freq='MS')
airpassengers_data = [
    112, 118, 132, 129, 121, 135, 148, 148, 136, 119, 104, 118,  # 1949
    115, 126, 141, 135, 125, 149, 170, 170, 158, 133, 114, 140,  # 1950
    135, 148, 178, 163, 158, 182, 209, 208, 191, 164, 149, 163,  # 1951
    172, 188, 214, 209, 195, 220, 246, 253, 227, 200, 170, 171,  # 1952
    190, 207, 230, 220, 210, 236, 258, 266, 245, 213, 188, 188,  # 1953
    211, 224, 250, 240, 225, 249, 276, 281, 259, 230, 205, 215,  # 1954
    225, 238, 268, 265, 245, 270, 300, 306, 280, 245, 222, 227,  # 1955
    246, 258, 289, 287, 260, 285, 318, 327, 299, 255, 236, 248,  # 1956
    262, 280, 317, 309, 287, 310, 345, 353, 324, 285, 258, 278,  # 1957
    286, 300, 339, 320, 298, 324, 355, 367, 340, 298, 267, 288,  # 1958
    302, 320, 362, 358, 332, 357, 398, 406, 378, 331, 298, 309,  # 1959
    310, 329, 380, 370, 350, 370, 411, 420, 391, 348, 310, 325   # 1960
]

# Create DataFrame with Date and Air Passengers
HarshArya = pd.DataFrame({'airpassengers': airpassengers_data}, index=date_range)

# 2. Check the structure and data type of AirPassengers
print("Structure and Data type of the dataset:")
print(HarshArya.info())  # Structure and data types

# 3. Check for missing values in the dataset
print("\nMissing values in the dataset:")
print(HarshArya.isna().sum())  # Missing values

# 4. Check for the starting date and ending date
print("\nStarting date and Ending date of the dataset:")
print("Start Date: ", HarshArya.index[0])
print("End Date: ", HarshArya.index[-1])

# 5. Check the frequency of the dataset
print("\nFrequency of the dataset:")
print(HarshArya.index.freq)  # Frequency of the dataset

# 6. Check for the summary of the dataset
print("\nSummary of the dataset:")
print(HarshArya.describe())  # Summary statistics

# 7. Plot the decomposition of the dataset
# Decompose the time series using statsmodels
decomposition_0098 = sm.tsa.seasonal_decompose(HarshArya['airpassengers'], model='multiplicative', period=12)

# Plot the decomposition
decomposition_0098.plot()
plt.suptitle("21BDS0098 - Decomposition of AirPassengers Data")
plt.show()

# 8. Plot the dataset
HarshArya['airpassengers'].plot(title="21BDS0098 - AirPassengers Dataset")
plt.xlabel('Date')
plt.ylabel('Number of Passengers')
plt.show()

# 9. Plot the time-series of the dataset (plot.ts equivalent)
plt.figure(figsize=(10, 6))
plt.plot(HarshArya.index, HarshArya['airpassengers'])
plt.title("21BDS0098 - Time Series Plot of AirPassengers")
plt.xlabel('Date')
plt.ylabel('Number of Passengers')
plt.show()

# 10. Draw the regressor line (Linear regression)
# Fit linear model
from sklearn.linear_model import LinearRegression

# Prepare the data for the regression line
HarshArya['time'] = np.arange(len(HarshArya))  # Create a time variable
X = HarshArya['time'].values.reshape(-1, 1)
y = HarshArya['airpassengers']

# Create and fit the model
model = LinearRegression()
model.fit(X, y)

# Predict the values using the model
y_pred = model.predict(X)

# Plot the data and the regression line
plt.figure(figsize=(10, 6))
plt.plot(HarshArya.index, HarshArya['airpassengers'], label='Air Passengers')
plt.plot(HarshArya.index, y_pred, color='red', label='Linear Trend Line')
plt.title("21BDS0098 - AirPassengers with Linear Trend Line")
plt.xlabel('Date')
plt.ylabel('Number of Passengers')
plt.legend()
plt.show()

# 11. Print the cycle across the years for the dataset
print("\nCycle across the years:")
print(HarshArya.index.to_period('M').month)  # Cycle (months)

# 12. Make the dataset stationary
# a. Log transformation
HarshArya['log_airpassengers'] = np.log(HarshArya['airpassengers'])

# Plot the log-transformed data
plt.figure(figsize=(10, 6))
plt.plot(HarshArya.index, HarshArya['log_airpassengers'])
plt.title("21BDS0098 - Log Transformation of AirPassengers")
plt.xlabel('Date')
plt.ylabel('Log of Number of Passengers')
plt.show()

# b. Differencing to make the data stationary
HarshArya['stationary'] = HarshArya['log_airpassengers'].diff().dropna()

# Plot the stationary data
plt.figure(figsize=(10, 6))
plt.plot(HarshArya.index[1:], HarshArya['stationary'][1:])
plt.title("21BDS0098 - Stationary Series (Differenced Log)")
plt.xlabel('Date')
plt.ylabel('Differenced Log of Passengers')
plt.show()

# 13. Plot a box plot across months for seasonal effect
plt.figure(figsize=(10, 6))
sns.boxplot(x=HarshArya.index.month, y=HarshArya['airpassengers'])
plt.title("21BDS0098 - Box Plot Across Months for Seasonal Effect")
plt.xlabel('Month')
plt.ylabel('Number of Passengers')
plt.show()

"""# **MODULE** **4**"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import skew, kurtosis

# Load the 'mpg' dataset from seaborn (which is a common dataset, similar to mtcars)
HarshArya = sns.load_dataset('mpg').dropna()  # Load 'mpg' dataset and remove rows with NaN values

# Display the first few rows of the dataset
print(HarshArya.head())

# Ensure the columns are numeric, checking for non-numeric values.
HarshArya = HarshArya.apply(pd.to_numeric, errors='coerce')

# Check column names to confirm the exact name of 'cyl' or equivalent
print(HarshArya.columns)

# 1. Measure of Central Tendency

## Mean (Arithmetic Mean)
mean_values_0098 = HarshArya.mean()
print("Mean for each variable:")
print(mean_values_0098)

## Median
median_values_0098 = HarshArya.median()
print("Median for each variable:")
print(median_values_0098)

## Quantiles (25%, 50%, 75%)
quantile_values_0098 = HarshArya.quantile([0.25, 0.5, 0.75])
print("Quantiles (25%, 50%, 75%) for each variable:")
print(quantile_values_0098)

## Deciles (using pd.qcut)
deciles_0098 = pd.qcut(HarshArya['mpg'], 10, labels=False) + 1  # Create deciles for 'mpg'
print("Deciles for mpg variable:")
print(deciles_0098.value_counts())

## Percentiles (10%, 50%, 90%)
percentile_values_0098 = HarshArya.quantile([0.1, 0.5, 0.9])
print("Percentiles (10%, 50%, 90%) for each variable:")
print(percentile_values_0098)

# 2. Measure of Dispersions

## Range (max - min)
range_values_0098 = HarshArya.max() - HarshArya.min()
print("Range for each variable:")
print(range_values_0098)

## Interquartile Range (IQR)
iqr_values_0098 = HarshArya.quantile(0.75) - HarshArya.quantile(0.25)
print("Interquartile Range (IQR) for each variable:")
print(iqr_values_0098)

## Interdecile Range (90th - 10th percentile)
interdecile_values_0098 = HarshArya.quantile(0.9) - HarshArya.quantile(0.1)
print("Interdecile Range for each variable:")
print(interdecile_values_0098)

## Standard Deviation
sd_values_0098 = HarshArya.std()
print("Standard Deviation for each variable:")
print(sd_values_0098)

## Variance
variance_values_0098 = HarshArya.var()
print("Variance for each variable:")
print(variance_values_0098)

## Skewness
skewness_values_0098 = HarshArya.apply(skew)
print("Skewness for each variable:")
print(skewness_values_0098)

## Kurtosis
kurtosis_values_0098 = HarshArya.apply(kurtosis)
print("Kurtosis for each variable:")
print(kurtosis_values_0098)

# 3. Frequency Distribution

## Frequency Distribution (Table)
freq_table_0098 = HarshArya.apply(pd.value_counts)
print("Frequency distribution for each variable:")
print(freq_table_0098)

## Histogram
plt.figure(figsize=(10, 8))

# Plot histogram for key numeric variables
plt.subplot(2, 2, 1)
HarshArya['mpg'].hist(color='skyblue', edgecolor='black')
plt.title('21BDS0098 - Histogram of MPG')
plt.xlabel('Miles per Gallon')
plt.ylabel('Frequency')

plt.subplot(2, 2, 2)
HarshArya['horsepower'].hist(color='lightgreen', edgecolor='black')
plt.title('21BDS0098 - Histogram of Horsepower')
plt.xlabel('Horsepower')
plt.ylabel('Frequency')

plt.subplot(2, 2, 3)
HarshArya['weight'].hist(color='lightcoral', edgecolor='black')
plt.title('21BDS0098 - Histogram of Weight')
plt.xlabel('Weight')
plt.ylabel('Frequency')

plt.subplot(2, 2, 4)
HarshArya['acceleration'].hist(color='lightyellow', edgecolor='black')
plt.title('21BDS0098 - Histogram of Acceleration')
plt.xlabel('Acceleration')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

## Relative Frequency Distribution
relative_freq_mpg_0098 = HarshArya['mpg'].value_counts(normalize=True)
print("Relative Frequency Distribution for MPG:")
print(relative_freq_mpg_0098)

## Cumulative Frequency Distribution
cumulative_freq_mpg_0098 = HarshArya['mpg'].value_counts().cumsum()
print("Cumulative Frequency Distribution for MPG:")
print(cumulative_freq_mpg_0098)

# 4. Categorical Variable Analysis

## Check if 'cylinders' column is available
if 'cylinders' in HarshArya.columns:
    # Pie Plot for number of cylinders (cylinders)
    cyl_counts_0098 = HarshArya['cylinders'].value_counts()
    plt.figure(figsize=(7, 7))
    cyl_counts_0098.plot.pie(autopct='%1.1f%%', colors=['lightblue', 'lightgreen', 'lightcoral'], startangle=90)
    plt.title('21BDS0098 - Pie Plot for Number of Cylinders')
    plt.ylabel('')
    plt.show()

    # Stacked Bar Plot for cylinders vs origin
    plt.figure(figsize=(8, 6))
    sns.countplot(x='cylinders', hue='origin', data=HarshArya, dodge=False, palette="Set2")
    plt.title("21BDS0098 - Stacked Bar Plot for Cylinders and Origin")
    plt.xlabel("Number of Cylinders")
    plt.ylabel("Count")
    plt.show()
else:
    print("Column 'cylinders' not found in the dataset.")

# 5. Summary of all measures (Mean, Median, etc.)
summary_stats_0098 = pd.DataFrame({
    'Mean': mean_values_0098,
    'Median': median_values_0098,
    'IQR': iqr_values_0098,
    'Standard Deviation': sd_values_0098,
    'Skewness': skewness_values_0098,
    'Kurtosis': kurtosis_values_0098
})
print("Summary Statistics for the dataset:")
print(summary_stats_0098)

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency
from mpl_toolkits.mplot3d import Axes3D
import plotly.express as px

# Load the Titanic dataset from seaborn (or use your own dataset)
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
HarshArya_0098 = pd.read_csv(url)

# Check the first few rows of the dataset to verify column names
print(HarshArya_0098.head())

# Check the column names to make sure 'Survived' is present
print("\nColumns in the dataset:")
print(HarshArya_0098.columns)

# Data Cleaning
# Fill missing values in 'Age' with the mean and in 'Embarked' with the mode (most frequent value)
HarshArya_0098['Age'].fillna(HarshArya_0098['Age'].mean(), inplace=True)
HarshArya_0098['Embarked'].fillna(HarshArya_0098['Embarked'].mode()[0], inplace=True)

# 3. Create a 2-way contingency table (Categorical vs Categorical)
Contingency_Table_0098 = pd.crosstab(HarshArya_0098['Sex'], HarshArya_0098['Survived'])
print("\nContingency Table (Categorical vs Categorical):")
print(Contingency_Table_0098)

# 4. Create a 3-way contingency table (Categorical vs Categorical vs Categorical)
Contingency_Table_3way_0098 = pd.crosstab([HarshArya_0098['Sex'], HarshArya_0098['Embarked']], HarshArya_0098['Survived'])
print("\n3-Way Contingency Table:")
print(Contingency_Table_3way_0098)

# 5. Apply row profile, column profile, and chi-square on one of the contingency tables
Chi2_0098, P_0098, Dof_0098, Expected_0098 = chi2_contingency(Contingency_Table_0098)
print(f"\nChi-Square Test Result:\nChi2: {Chi2_0098}, P-value: {P_0098}, Degrees of Freedom: {Dof_0098}")
print("Expected Frequencies:")
print(Expected_0098)

# Row profile
Row_Profile_0098 = Contingency_Table_0098.div(Contingency_Table_0098.sum(axis=1), axis=0)
print("\nRow Profile (Proportions per Row):")
print(Row_Profile_0098)

# Column profile
Column_Profile_0098 = Contingency_Table_0098.div(Contingency_Table_0098.sum(axis=0), axis=1)
print("\nColumn Profile (Proportions per Column):")
print(Column_Profile_0098)

# Relative Frequency
Relative_Frequency_0098 = Contingency_Table_0098 / Contingency_Table_0098.sum().sum()
print("\nRelative Frequency Table:")
print(Relative_Frequency_0098)

# 6. Scatter Plot (Categorical vs Numerical)
sns.scatterplot(x='Age', y='Fare', hue='Survived', data=HarshArya_0098)
plt.title('Scatter Plot: Age vs Fare with Survival Status')
plt.show()

# 7. Scatter Plot for 3 Variables (Age, Fare, and Pclass)
sns.scatterplot(x='Age', y='Fare', hue='Survived', style='Pclass', data=HarshArya_0098)
plt.title('3D Scatter Plot: Age, Fare, and Pclass')
plt.show()

# 8. Change color, shape, and add horizontal bars to the scatter plot
sns.scatterplot(x='Age', y='Fare', hue='Survived', style='Sex', data=HarshArya_0098)
plt.title('Scatter Plot: Age vs Fare with Survival and Gender')
plt.show()

# 9. 3D Scatter Plot (Age, Fare, and Pclass as 3D Axes)
fig_0098 = plt.figure()
ax_0098 = fig_0098.add_subplot(111, projection='3d')
ax_0098.scatter(HarshArya_0098['Age'], HarshArya_0098['Fare'], HarshArya_0098['Pclass'], c=HarshArya_0098['Survived'], cmap='coolwarm')
ax_0098.set_xlabel('Age')
ax_0098.set_ylabel('Fare')
ax_0098.set_zlabel('Pclass')
plt.title('3D Scatter Plot: Age, Fare, and Pclass')
plt.show()

# 10. 2D Boxplot (Categorical vs Numerical)
sns.boxplot(x='Survived', y='Age', data=HarshArya_0098)
plt.title('Boxplot: Survival vs Age')
plt.show()

# 11. Radar Chart (Sunray Plot) using 'Pclass', 'Age', 'Fare', 'SibSp', 'Parch'
Categories_0098 = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']  # Example categories
Values_0098 = [
    HarshArya_0098['Pclass'].mode()[0],   # Mode of Pclass (most frequent class)
    HarshArya_0098['Age'].mean(),         # Mean Age
    HarshArya_0098['Fare'].mean(),        # Mean Fare
    HarshArya_0098['SibSp'].mean(),       # Mean of SibSp (siblings/spouses aboard)
    HarshArya_0098['Parch'].mean()        # Mean of Parch (parents/children aboard)
]

# To close the radar chart, append the first value to the end of the list
Values_0098.append(Values_0098[0])  # Append first value to make the list a circle

# Calculate angle for each axis (360 degrees divided by number of categories)
Angles_0098 = np.linspace(0, 2 * np.pi, len(Categories_0098), endpoint=False).tolist()

# Append the first angle to close the circle (it must match the first value of 'Values')
Angles_0098.append(Angles_0098[0])  # Ensure the loop is closed by adding the first angle to the end of Angles

# Create Radar chart data setup
fig_0098 = plt.figure(figsize=(6, 6))
ax_0098 = fig_0098.add_subplot(111, polar=True)

# Plot the data
ax_0098.fill(Angles_0098, Values_0098, color='skyblue', alpha=0.25)  # Fill the area
ax_0098.plot(Angles_0098, Values_0098, color='blue', linewidth=2)  # Line around the plot

# Set the y-axis labels (empty because we're not showing radial values)
ax_0098.set_yticklabels([])

# Set the x-ticks to be the category labels
ax_0098.set_xticks(Angles_0098[:-1])  # Exclude last angle to avoid repetition
ax_0098.set_xticklabels(Categories_0098)

# Title and showing the plot
plt.title("21BDS0098 - Sunray Plot (Radar Chart)")
plt.show()

"""# **MODULE 5**"""

# Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Load the dataset
# For demonstration, let's assume the dataset is available as 'Mall_Customers.csv'
# Replace this path with the actual file path
HarshArya_0098 = pd.read_csv('Mall_Customers.csv')

# Displaying the first few rows of the dataset to understand its structure
print(HarshArya_0098.head())

# Extracting 4th and 5th columns (assuming the columns are 'Annual Income' and 'Spending Score')
X_0098 = HarshArya_0098.iloc[:, [3, 4]].values  # Select 4th and 5th columns as features

# Feature Scaling - Standardize the data before clustering
scaler_0098 = StandardScaler()
X_scaled_0098 = scaler_0098.fit_transform(X_0098)

# Elbow Method to find the optimal number of clusters
wcss_0098 = []  # List to store the within-cluster sum of squares (WCSS)
for i in range(1, 11):  # Try from 1 to 10 clusters
    kmeans_0098 = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)
    kmeans_0098.fit(X_scaled_0098)
    wcss_0098.append(kmeans_0098.inertia_)  # WCSS is the inertia value

# Plotting the elbow graph to determine the optimal number of clusters
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss_0098, marker='o', color='blue')
plt.title('Elbow Method for Optimal Number of Clusters (HarshArya_0098)')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.grid(True)
plt.show()

# From the plot, you can visually determine the optimal number of clusters.
# Let's assume it's 5 (you should adjust based on the elbow plot observation).
optimal_clusters_0098 = 5

# Fitting KMeans to the dataset with the optimal number of clusters
kmeans_0098 = KMeans(n_clusters=optimal_clusters_0098, init='k-means++', max_iter=300, n_init=10, random_state=42)
y_kmeans_0098 = kmeans_0098.fit_predict(X_scaled_0098)

# Visualizing the clusters

# Plotting the clusters
plt.figure(figsize=(10, 6))
plt.scatter(X_scaled_0098[y_kmeans_0098 == 0, 0], X_scaled_0098[y_kmeans_0098 == 0, 1], s=100, c='red', label='Cluster 1')
plt.scatter(X_scaled_0098[y_kmeans_0098 == 1, 0], X_scaled_0098[y_kmeans_0098 == 1, 1], s=100, c='blue', label='Cluster 2')
plt.scatter(X_scaled_0098[y_kmeans_0098 == 2, 0], X_scaled_0098[y_kmeans_0098 == 2, 1], s=100, c='green', label='Cluster 3')
plt.scatter(X_scaled_0098[y_kmeans_0098 == 3, 0], X_scaled_0098[y_kmeans_0098 == 3, 1], s=100, c='cyan', label='Cluster 4')
plt.scatter(X_scaled_0098[y_kmeans_0098 == 4, 0], X_scaled_0098[y_kmeans_0098 == 4, 1], s=100, c='magenta', label='Cluster 5')

# Plot the centroids
plt.scatter(kmeans_0098.cluster_centers_[:, 0], kmeans_0098.cluster_centers_[:, 1], s=300, c='yellow', label='Centroids')
plt.title('K-Means Clustering (HarshArya_0098)')
plt.xlabel('Annual Income (scaled)')
plt.ylabel('Spending Score (scaled)')
plt.legend()
plt.grid(True)
plt.show()

# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler

# Load the dataset (Make sure to replace this path with the correct path)
HarshArya_0098 = pd.read_csv('Mall_Customers.csv')

# Display the first few rows to understand the structure of the dataset
print(HarshArya_0098.head())

# Check for missing values
print(HarshArya_0098.isnull().sum())

# Data Cleaning - Drop rows with missing values (if any)
HarshArya_0098 = HarshArya_0098.dropna()

# Select relevant columns - 'Annual Income' and 'Spending Score'
HarshArya_0098_dataset = HarshArya_0098[['Annual Income (k$)', 'Spending Score (1-100)']]

# Standardize the data before clustering
scaler_0098 = StandardScaler()
HarshArya_0098_dataset_scaled = scaler_0098.fit_transform(HarshArya_0098_dataset)

# Statistical summary
print("Statistical Summary:\n")
print(HarshArya_0098_dataset.describe())

# Compute the distance matrix using Euclidean method
distance_matrix_euclidean_0098 = pdist(HarshArya_0098_dataset_scaled, metric='euclidean')
distance_matrix_euclidean_0098 = squareform(distance_matrix_euclidean_0098)
print("Distance Matrix (Euclidean):\n", distance_matrix_euclidean_0098)

# Perform Hierarchical Clustering using Euclidean distance and ward.D method
Z_euclidean_0098 = linkage(HarshArya_0098_dataset_scaled, method='ward', metric='euclidean')

# Plotting the Dendrogram for Euclidean distance
plt.figure(figsize=(10, 6))
dendrogram(Z_euclidean_0098)
plt.title('Dendrogram (Euclidean Distance)')
plt.xlabel('Customers')
plt.ylabel('Euclidean Distance')
plt.show()

# Compute the distance matrix using Manhattan method
distance_matrix_manhattan_0098 = pdist(HarshArya_0098_dataset_scaled, metric='cityblock')
distance_matrix_manhattan_0098 = squareform(distance_matrix_manhattan_0098)
print("Distance Matrix (Manhattan):\n", distance_matrix_manhattan_0098)

# Perform Hierarchical Clustering using Manhattan distance and average method
Z_manhattan_0098 = linkage(HarshArya_0098_dataset_scaled, method='average', metric='cityblock')

# Plotting the Dendrogram for Manhattan distance
plt.figure(figsize=(10, 6))
dendrogram(Z_manhattan_0098)
plt.title('Dendrogram (Manhattan Distance)')
plt.xlabel('Customers')
plt.ylabel('Manhattan Distance')
plt.show()

# Compute the distance matrix using Maximum method
distance_matrix_maximum_0098 = pdist(HarshArya_0098_dataset_scaled, metric='chebyshev')
distance_matrix_maximum_0098 = squareform(distance_matrix_maximum_0098)
print("Distance Matrix (Maximum):\n", distance_matrix_maximum_0098)

# Perform Hierarchical Clustering using Maximum distance and average method
Z_maximum_0098 = linkage(HarshArya_0098_dataset_scaled, method='average', metric='chebyshev')

# Plotting the Dendrogram for Maximum distance
plt.figure(figsize=(10, 6))
dendrogram(Z_maximum_0098)
plt.title('Dendrogram (Maximum Distance)')
plt.xlabel('Customers')
plt.ylabel('Maximum Distance')
plt.show()

# Compute the distance matrix using Canberra method
distance_matrix_canberra_0098 = pdist(HarshArya_0098_dataset_scaled, metric='canberra')
distance_matrix_canberra_0098 = squareform(distance_matrix_canberra_0098)
print("Distance Matrix (Canberra):\n", distance_matrix_canberra_0098)

# Perform Hierarchical Clustering using Canberra distance and average method
Z_canberra_0098 = linkage(HarshArya_0098_dataset_scaled, method='average', metric='canberra')

# Plotting the Dendrogram for Canberra distance
plt.figure(figsize=(10, 6))
dendrogram(Z_canberra_0098)
plt.title('Dendrogram (Canberra Distance)')
plt.xlabel('Customers')
plt.ylabel('Canberra Distance')
plt.show()

# Compute the distance matrix using Binary method
distance_matrix_binary_0098 = pdist(HarshArya_0098_dataset_scaled, metric='jaccard')
distance_matrix_binary_0098 = squareform(distance_matrix_binary_0098)
print("Distance Matrix (Binary):\n", distance_matrix_binary_0098)

# Perform Hierarchical Clustering using Binary distance and average method
Z_binary_0098 = linkage(HarshArya_0098_dataset_scaled, method='average', metric='jaccard')

# Plotting the Dendrogram for Binary distance
plt.figure(figsize=(10, 6))
dendrogram(Z_binary_0098)
plt.title('Dendrogram (Binary Distance)')
plt.xlabel('Customers')
plt.ylabel('Binary Distance')
plt.show()

# Compute the distance matrix using Minkowski method (p=3, typical choice for Minkowski distance)
distance_matrix_minkowski_0098 = pdist(HarshArya_0098_dataset_scaled, metric='minkowski', p=3)
distance_matrix_minkowski_0098 = squareform(distance_matrix_minkowski_0098)
print("Distance Matrix (Minkowski):\n", distance_matrix_minkowski_0098)

# Perform Hierarchical Clustering using Minkowski distance and average method
Z_minkowski_0098 = linkage(HarshArya_0098_dataset_scaled, method='average', metric='minkowski')

# Plotting the Dendrogram for Minkowski distance
plt.figure(figsize=(10, 6))
dendrogram(Z_minkowski_0098)
plt.title('Dendrogram (Minkowski Distance)')
plt.xlabel('Customers')
plt.ylabel('Minkowski Distance')
plt.show()

"""# **MODULE 6**"""

# Step 1: Install and import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn import datasets

# Step 2: Load the dataset
# Replace 'mall_customer.csv' with the actual file path if needed
HarshArya_0098 = pd.read_csv("Mall_Customers.csv")

# Display the first few rows of the dataset to understand its structure
print(HarshArya_0098.head())

# Assuming that the numeric columns are 'Annual Income (k$)' and 'Spending Score (1-100)'
# If column names are different, make sure to update the column names accordingly.

# Step 3: Data Preprocessing (Selecting only numeric columns for PCA)
# We assume 'Annual Income (k$)' and 'Spending Score (1-100)' are the numeric columns.
data_0098 = HarshArya_0098[['Annual Income (k$)', 'Spending Score (1-100)']]

# Step 4: Standardizing the data (important for PCA)
scaler_0098 = StandardScaler()
data_scaled_0098 = scaler_0098.fit_transform(data_0098)

# Step 5: Perform PCA
pca_0098 = PCA()
pca_result_0098 = pca_0098.fit_transform(data_scaled_0098)

# Step 6: Print PCA results - Eigenvalues (explained variance) and loadings
print("\nEigenvalues (Explained Variance):")
print(pca_0098.explained_variance_)

print("\nExplained Variance Ratio (Percentage of variance explained by each component):")
print(pca_0098.explained_variance_ratio_)

print("\nPCA Components (Loadings):")
print(pca_0098.components_)

# Step 7: Plot the explained variance ratio (Scree plot)
plt.figure(figsize=(8,6))
plt.plot(range(1, len(pca_0098.explained_variance_ratio_) + 1), pca_0098.explained_variance_ratio_, marker='o', linestyle='--')
plt.title("Scree Plot")
plt.xlabel("Principal Component")
plt.ylabel("Explained Variance Ratio")
plt.grid(True)
plt.show()

# Step 8: Visualizing the first two principal components
plt.figure(figsize=(8,6))
sns.scatterplot(x=pca_result_0098[:, 0], y=pca_result_0098[:, 1], palette='viridis')
plt.title("PCA - First Two Principal Components")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.grid(True)
plt.show()

# Step 9: Plot the first two components as a biplot (variables and individuals)
plt.figure(figsize=(8, 6))
sns.scatterplot(x=pca_result_0098[:, 0], y=pca_result_0098[:, 1], color='blue', label='Individuals')

# Plotting the components (loadings) on the same plot
for i, feature in enumerate(data_0098.columns):
    plt.arrow(0, 0, pca_0098.components_[0][i], pca_0098.components_[1][i], color='red', alpha=0.5)
    plt.text(pca_0098.components_[0][i] * 1.2, pca_0098.components_[1][i] * 1.2, feature, color='red', ha='center', va='center')

plt.title("PCA - Biplot")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.grid(True)
plt.show()

# Step 10: Summary of PCA results
print("\nSummary of PCA:")
print("Explained Variance (Eigenvalues):", pca_0098.explained_variance_)
print("Explained Variance Ratio:", pca_0098.explained_variance_ratio_)
print("Cumulative Explained Variance:", np.cumsum(pca_0098.explained_variance_ratio_))

# Based on the Scree plot, decide how many components to keep (usually the first few with eigenvalues > 1 or that explain most of the variance).
# We can check how many components are required to explain, say 90% of the variance.

cumulative_variance_0098 = np.cumsum(pca_0098.explained_variance_ratio_)
print("Cumulative Variance Explained by Top Components:", cumulative_variance_0098)

# Example: Selecting the first two components (if they explain most of the variance)
n_comp_0098 = 2
pca_result_selected_0098 = pca_result_0098[:, :n_comp_0098]

# Visualize the selected PCA components
plt.figure(figsize=(8,6))
sns.scatterplot(x=pca_result_selected_0098[:, 0], y=pca_result_selected_0098[:, 1], palette='viridis')
plt.title("Selected PCA - First Two Components")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.grid(True)
plt.show()